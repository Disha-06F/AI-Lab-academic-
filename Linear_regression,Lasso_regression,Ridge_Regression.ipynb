{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee9f2c7-86bc-4b6b-9924-75dfc16b1d16",
   "metadata": {},
   "source": [
    "### <span style='color:Red'>Linear Regression </span>\n",
    "###### mean squared error(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bcf968-60e0-4d41-94a1-6ea5afe4397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba1499-f4c9-4ea6-9eab-24ebf1da1216",
   "metadata": {},
   "source": [
    "##### sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ea234b-56f4-40f3-8fc2-2d3517547e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n",
      "[2 4 5 4 5]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1],[2],[3],[4],[5]])\n",
    "print(x)\n",
    "y=np.array([2,4,5,4,5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59ff642-7edd-4573-81a5-830a4dee7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9235bce-d821-4b96-ac96-8f9fd739eb77",
   "metadata": {},
   "source": [
    "##### Mean Squared Error (MSE)\n",
    "### MSE=1/n∑(yi−y^i)2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1491d85-05e0-42bb-b2e5-f7c3d0f9c542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: [4]\n",
      "y_pred: [3.14285714]\n",
      "Mean squared Error on test data: 0.7346938775510206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)\n",
    "mse=mean_squared_error(y_test,y_pred)\n",
    "print(\"y_test:\",y_test)\n",
    "print(\"y_pred:\",y_pred)\n",
    "print(\"Mean squared Error on test data:\",mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4c3f6-4fad-4927-b3a3-f3d4c7c45333",
   "metadata": {},
   "source": [
    "#### Predicted = 3.14\n",
    "#### Actual = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbc43e-af31-4a69-ac5c-c918f9a36907",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "##### Lasso regression is Linear Regression with L1 regularization:\n",
    "#### J(β)=∑(yi−y^i)2+λ∑∣βj∣"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e944df3-d3b3-4429-9578-2803e522ec58",
   "metadata": {},
   "source": [
    "#### Lasso stands for Least Absolute Shrinkage and Selection Operator. It is a type of linear regression that includes L1 regularization.\n",
    "### loss = ∑(yi- yi^)^2 + α ∑|Wj|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc412a9d-6b31-45bb-b37d-20e0a65a0939",
   "metadata": {},
   "source": [
    "### Alpha (α)\n",
    "##### Alpha is the regularization parameter in Lasso.\n",
    "##### Controls the strength of the penalty on coefficients:\n",
    "\n",
    "##### α = 0 → Lasso becomes ordinary linear regression (no penalty).\n",
    "##### α large → Stronger penalty → more coefficients shrink to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042e163-b971-4f30-9492-ffbefa9a075d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "x=np.array([[1],[2],[3],[4],[5]])\n",
    "y=np.array([2,3,5,7,11])\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f03c2-0f0f-4ddc-892c-252b794b1658",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5b0c4c5-107c-4093-ac42-8f33c8e7aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lasso Regression:\n",
      "Predictions: [3.62857143]\n",
      "MSE: 0.39510204081632594\n",
      "R2 score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda for jupyter\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_model=Lasso(alpha=0.1)\n",
    "lasso_model.fit(x_train,y_train)\n",
    "y_pred_lasso=lasso_model.predict(x_test)\n",
    "print(\"\\n Lasso Regression:\")\n",
    "print(\"Predictions:\", y_pred_lasso)\n",
    "print(\"MSE:\",mean_squared_error(y_test,y_pred_lasso))\n",
    "print(\"R2 score:\",r2_score(y_test,y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f08d0-0ca5-497f-a243-0c6aa50747ce",
   "metadata": {},
   "source": [
    "#### R² score tells you how well your model fits the data.\n",
    "#### R² = 1 → perfect prediction, 0 → predicts just the mean, negative → worse than mean.\n",
    "#### NaN appears if your test set has only 1 sample, because variance of a single number = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d087a4-eb24-4e59-bbbc-a35080db54be",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "##### Ridge Regression is a type of linear regression that includes L2 regularization. It’s used to prevent overfitting when your features are correlated or when you have many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "776772d3-0b00-4c56-a945-44a8df9843c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "Predictions:  [3.84615385]\n",
      "MSE: 0.7159763313609476\n",
      "R2 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda for jupyter\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model=Ridge(alpha=1.0)\n",
    "ridge_model.fit(x_train,y_train)\n",
    "y_pred_ridge=ridge_model.predict(x_test)\n",
    "print(\"Ridge Regression\")\n",
    "print(\"Predictions: \" ,y_pred_ridge)\n",
    "print(\"MSE:\", mean_squared_error(y_test,y_pred_ridge))\n",
    "print(\"R2 Score:\",r2_score(y_test,y_pred_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e9002-871a-4e3a-be53-53e7e947630c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
